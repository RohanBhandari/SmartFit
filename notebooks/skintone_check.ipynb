{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Tone Check\n",
    "### This notebook implements a simple way to check whether the clothing transfer network generates skin with color that matches the input image.  If not, the image can either not be returned to the user or an image from a backup method (e.g. a 2D overlay) can be returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage: To replicate the results of this notebook, run the cells after setting up the repository and running the test example as defined in the README. Optionally run the human parsing step on the output image as well, if using the `out_seg_path` flag in `get_skintone_similarity`, as described below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import io\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that returns a mask that selects just the arms of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_arm_mask(image_path):\n",
    "    # Load segmentations and keep only the arms\n",
    "    mask = io.loadmat(image_path)\n",
    "    mask = misc.imresize(mask['segment'], (256,192))\n",
    "    mask = np.array(((mask==14)|(mask==15)), dtype='uint8')\n",
    "    mask *= 255 # Follow PIL mask conventions (0=mask, 255=keep)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns a unit-normalized color histogram of the masked image.\n",
    "#### The histogram corresponds to a 768-dimensional (256 pixel values * 3 channels) vector representation of the color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_color_histogram(image, mask):\n",
    "    im = Image.fromarray(image)\n",
    "    mask = Image.fromarray(mask)\n",
    "    hist = im.histogram(mask)\n",
    "    # Normalize histogram\n",
    "    hist = np.asarray(hist, dtype=float)\n",
    "    hist /= np.linalg.norm(hist)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function that masks the image and gets two color histograms (one for the input and output image). It then returns the dot product between the two unit-normalized histograms, which is an estimate of the color similarity\n",
    "\n",
    "#### The segmentation of the output image (out_seg_path) is an optional argument. If it is not included, the output image will be masked with the input image arm mask. While this will not match the output exactly (as the model may generate the arms slightly differently than in the input image), it will be a good approximation and removes the need to run the segmentation model a second time on the output image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_skintone_similarity(in_pic_path, in_seg_path, out_pic_path, out_seg_path=''):\n",
    "    # Load and resize images\n",
    "    in_pic = misc.imread(in_pic_path)\n",
    "    in_pic = misc.imresize(in_pic, (256, 192, 3))\n",
    "\n",
    "    out_pic = misc.imread(out_pic_path)\n",
    "    out_pic = misc.imresize(out_pic, (256, 192, 3))\n",
    "    \n",
    "    # Load segment and return arm mask\n",
    "    in_mask  = get_arm_mask(in_seg_path)\n",
    "    if out_seg_path:\n",
    "        out_mask = get_arm_mask(out_seg_path)\n",
    "    else:\n",
    "        out_mask = in_mask\n",
    "    \n",
    "    # Get color histograms of arms\n",
    "    in_hist  = get_color_histogram(in_pic, in_mask)\n",
    "    out_hist = get_color_histogram(out_pic, out_mask)\n",
    "    \n",
    "    # Return dot product of histograms\n",
    "    return np.dot(in_hist, out_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "#### Running the check on the same input and output image should result in a score of 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_skintone_similarity('../inputs/example_person.jpg',\n",
    "                        '../human_parsing/output/example_person.mat',\n",
    "                        '../inputs/example_person.jpg',\n",
    "                        '../human_parsing/output/example_person.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare input and output image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run without parsing the output image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52816183930138871"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_skintone_similarity('../inputs/example_person.jpg',\n",
    "                        '../human_parsing/output/example_person.mat',\n",
    "                        '../output/example_output.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run with parsing the output image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59188054857848238"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_skintone_similarity('../inputs/example_person.jpg',\n",
    "                        '../human_parsing/output/example_person.mat',\n",
    "                        '../output/example_output.png',\n",
    "                        '../human_parsing/output/example_output.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
